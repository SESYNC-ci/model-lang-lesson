---
---

## Linear Mixed Models

The [lme4](){:.rlib} package expands the formula "mini-language" to allow
descriptions of "random effects".

- normal predictors are "fixed effects"
- `(...|...)` expressions describe "random effects"

In the context of this package, variables
added to the right of the `~` in the usual way are "fixed effects"---they
consume a well-defined number of degrees of freedom. Variables added within
`(...|...)` are "random effects".
{:.notes}

===

Models with random effects should be understood as specifying multiple,
overlapping probability statements about the observations.

$$
\begin{align}
&\log(WAGP_i) \sim Normal(\mu_i, \sigma_0^2) \\
&\mu_i = \beta_0 + \boldsymbol{\beta_1}[OCCP_i] + \beta_2 \log(SCHL_i) \\
&\boldsymbol{\beta_1} \sim Normal(0, \boldsymbol{\Sigma_1}) \\
&\end{align}
$$

===

The "random intercepts" and "random slopes" models are the two most common
extensions to a formula with one variable.

| Formula                  | Description |
|--------------------------|-------------|
| `y ~ (1 | b) + a`        | random intercept for each level in `b` |
| `y ~ a + (a | b)`        | random intercept and slope w.r.t. `a` for each level in `b` |

===

### Random Intercept

The `lmer` function fits linear models with the [lme4](){:.rlib} extensions to
the `lm` formula syntax.


```{r, message = FALSE, handout = 0}
library(lme4)
fit <- lmer(
  log(WAGP) ~ (1|OCCP) + SCHL,
  data = pums)
```

===

```{r lmer_ri_summary}
summary(fit)
```

The familiar assessment of model residuals is absent from the summary due to the
lack of a widely accepted measure of null and residual deviance. The notions of
model saturation, degrees of freedom, and independence of observations have all
crossed onto thin ice.
{:.notes}

In a `lm` or `glm` fit, each response is conditionally independent, given it's
predictors and the model coefficients. Each observation corresponds to it's own
probability statement. In a model with random effects, each response is no
longer conditionally independent, given it's predictors and model coefficients.
{:.notes}

===

### Random Slope

Adding a numeric variable on the left of a grouping specified with `(...|...)`
produces a "random slope" model. Here, separate coefficients for hours worked
are allowed for each level of education.

```{r, handout = 0}
fit <- lmer(
  log(WAGP) ~ (WKHP | SCHL),
  data = pums)
```

===

The warning that the procedure `failed to converge` is worth paying attention
to. In this case, we can proceed by switching to the slower numerical optimizer
that [lme4](){:.rlib} previously used by default.

```{r, handout = 0}
fit <- lmer(
  log(WAGP) ~ (WKHP | SCHL),
  data = pums, 
  control = lmerControl(optimizer = "bobyqa"))
```

```{r}
summary(fit)
```

===

The `predict` function extracts model predictions from a fitted model object
(i.e. the output of `lm`, `glm`, `lmer`, and `glmer`), providing one easy
way to visualize the effect of estimated coefficients.

```{r, handout = 0}
ggplot(pums,
  aes(x = WKHP, y = log(WAGP), color = SCHL)) +
  geom_point() +
  geom_line(aes(y = predict(fit))) +
  labs(title = 'Random intercept and slope with lmer')
```

===

### Generalized Mixed Models

The `glmer` function adds upon `lmer` the option to specify the same group of
exponential family distributions for the residuals available to `glm`.
