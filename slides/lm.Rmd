---
---

## Linear Regression

With the US Census data, we will use a linear regression to determine the relationship between educational attainment (`SCHL`) and wages (`WAGP`). The basic function for fitting a regression in R is the `lm()` function,
standing for linear model.

```{r, handout = 0}
fit <- lm(
  formula = WAGP ~ SCHL,
  data = pums)
```

The `lm()` function takes a formula argument and a data argument, and computes
the best fitting linear model (i.e. determines coefficients that [minimize the
sum of squared residuals].
{:.notes}

[minimize the sum of squared residuals]: https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)

===

Data visualizations can help confirm intuition, but only with very simple
models, typically with just one or two "fixed effects".

```{r}
library(ggplot2)

ggplot(pums,
  aes(x = SCHL, y = WAGP)) +
  geom_boxplot()
```

===

Within the formula expressions, data transformation functions can also be used. 

| Formula      | Description |
|--------------|-------------|
| `y ~ log(a)` | log transformed variable |
| `y ~ sin(a)` | periodic function of a variable |
| `y ~ I(a*b)` | product of variables, protected by `I` from expansion |

===

The `WAGP` variable is always positive and includes some values that
are many orders of magnitude larger than the mean. Therefore, we can log transform the wages in the model.

```{r lm_weight, handout = 0}
fit <- lm(
  log(WAGP) ~ SCHL,
  pums)
```

```{r}
summary(fit)
```

===

## Predictor class

For the predictors in a linear model, there is a big difference between factors and numbers.

===

Compare the model above which fit the wages and level of education (a factor) with one that uses age (a numerical category)

```{r, handout = 0}
fit <- lm(
  log(WAGP) ~ AGEP,
  pums)
```

```{r}
summary(fit)
```

In the model with `SCHL`, multiple intercepts are fit. However, in the model with `AGEP`, a slope is fit.
{:.notes}
