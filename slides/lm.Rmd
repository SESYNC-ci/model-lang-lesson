---
---

## Linear Regression

We will use a linear regression to determine the relationship between educational attainment (`SCHL`) and wages (`WAGP`). The basic function for fitting a regression in R is the `lm()` function,
standing for linear model.

```{r, handout = 0}
fit <- lm(
  formula = WAGP ~ SCHL,
  data = pums)
```

The `lm()` function takes a formula argument and a data argument, and computes
the best fitting linear model (i.e. determines coefficients that [minimize the
sum of squared residuals].
{:.notes}

[minimize the sum of squared residuals]: https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)

===

Data visualizations can help confirm intuition, but only with very simple
models, typically with just one or two "fixed effects".

```{r}
library(ggplot2)

ggplot(pums,
  aes(x = SCHL, y = WAGP)) +
  geom_boxplot()
```

===

Data transformation functions are allowed within the formula expression.

| Formula      | Description |
|--------------|-------------|
| `y ~ log(a)` | log transformed variable |
| `y ~ sin(a)` | periodic function of a variable |
| `y ~ I(a*b)` | product of variables, protected by `I` from expansion |

===

The `WAGP` variable is always positive and includes some values that
are many orders of magnitude larger than the mean.

```{r lm_weight, handout = 0}
fit <- lm(
  log(WAGP) ~ SCHL,
  pums)
```

```{r}
summary(fit)
```

===

## Metadata Matters

For the predictors in a linear model, there is a big difference between factors
and numbers.

```{r, handout = 0}
fit <- lm(
  log(WAGP) ~ AGEP,
  pums)
```

```{r}
summary(fit)
```

The difference between 1 and 5 model degrees of freedom between the last two
summaries---with one fixed effect each---arises because `SCHL` is a a factor
while `AGEP` is numeric. In the first case you get multiple intercepts,
while in the second case you get a slope.
{:.notes}
