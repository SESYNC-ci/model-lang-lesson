---
---

## Linear Mixed Models

The [lme4](){:.rlib} package expands the formula "mini-language" to allow
descriptions of "random effects".

- normal predictors are "fixed effects"
- `(...|...)` expressions describe "random effects"

In the context of this package, variables
added to the right of the `~` in the usual way are "fixed effects"---they
consume a well-defined number of degrees of freedom. Variables added within
`(...|...)` are "random effects".
{:.notes}

===

The "random intercepts" and "random slopes" models are the two most common
extensions to a formula with one variable.

| Formula               | Description                                                     |
|-----------------------|-----------------------------------------------------------------|
| `y ~ a`               | constant and one fixed effect                                   |
| `y ~ (1 | b) + a`     | random intercept for each level in `b` and one fixed effect     |
| `y ~ a + (a | b)`     | random intercept and slope w.r.t. `a` for each level in `b`                  |

===

## Random intercept

The `lmer` and `glmer` functions fit linear and generalized linear models with
the `lme4` formula syntax.

```{r lmer_ri, message = FALSE, title = '{{ site.handouts[0] }}'}
library(lme4)
fit <- lmer(
  hindfoot_length ~ (1|species_id) + log(weight),
  data = animals)
```

===

```{r lmer_ri_summary}
summary(fit)
```

The familiar assessment of model residuals is absent from the summary due to the lack of a widely accepted measure of null and residual deviance. The notions of model saturation, degrees of freedom, and independence of observations have all crossed onto thin ice.
{:.notes}

===

## Non-independence

Models with random effects should be understood as specifying multiple,
overlapping probability statements about the observations.

$$
\begin{align}
&hindfoot\_length_i \sim Normal(\mu_i, \sigma_0^2) \\
&\mu_i = \beta_0 + \beta_1[species\_id_i] + \beta_2 \log(weight_i) \\
&\beta_1[j] \sim Normal(0, \sigma_1^2) \\
&\end{align}
$$

In a `lm` or `glm` fit, each response is conditionally independent, given it's predictors and the model coefficients. Each observation corresponds to it's own probability statement. In a model with random effects, each response is no longer conditionally independent, given it's predictors and model coefficients.
{:.notes}

===

## Exercise 4

Write down the formula for a random intercepts model with a fixed effect of
sex and a random effect of plot on each animal's weight.

[View solution](#solution-4)
{:.notes}

===

## Random slope

Adding a numeric variable on the left of a grouping specified with `(...|...)` produces a "random slope" model. Here, separate coefficients for hindfoot_length are allowed for each species.

```{r, title = '{{ site.handouts[0] }}'}
fit <- lmer(
  hindfoot_length ~ 
    log(weight) + (log(weight) | species_id),
  data = animals)
```

===

```{r}
summary(fit)
```

===

```{r rs_plot, echo = FALSE, eval = FALSE}
library(ggplot2)
library(dplyr)
prune_animals <- na.omit(select(animals, hindfoot_length, weight, species_id))
fit <- lmer(
  hindfoot_length ~ log(weight) + (log(weight) | species_id),
  data = prune_animals)
ggplot(
  prune_animals,
  aes(x = log(weight), y = hindfoot_length, color = species_id)) +
  geom_point() +
  geom_line(aes(y = predict(fit))) +
  labs(title = 'Random intercept and slope with lmer')
```

![]({{ site.baseurl }}/images/rs_plot-1.png)

===

## Generalized Mixed Models

The `glmer` function merely adds to `lmer` the option to specify an exponential
family distribution for the response variable.
